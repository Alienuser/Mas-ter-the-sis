\section{Umsetzung}
Hier noch generell was beschreiben. - Zielarchitekturbild darstellen (komplette Architektur)

\subsection{Cloud}
Wie habe ich das nun in der Cloud umgesetzt?\\
Es gibt vier Möglichkeiten:\\
- Machine Learning Models (Autoamtisch aus Daten generrieren)\\
- Model flows (SPSS) - Make Deployment\\
- Model flows (SPSS) - Download Model - Import Tensorflow/Tensorflow.JS\\
- Notebooks (Python)

Volgende Schritte müssen durchgeführt werden:\\
- Daten zusammenstellen\\
- Daten überprüfen\\
- Daten in Watson Studio importieren\\
- Daten in CSV überführen (Data flows)\\
- Watson Machine Learning model anlegen\\
- Model bearbeiten und neuronales Netz hinzufügen\\
- Modell trainieren lassen\\
- Modell exportieren (Tabelle)\\
- Deployment machen\\
- REST-Schnittstelle austesten und Daten hinschicken

\url{https://console.bluemix.net/docs/cli/index.html#overview}

\subsubsection{Testen mit Postman}
Hier wird das mit Postman getestet.

\subsection{Tensorflow}
Einrichten der NodeJS-Umgebung auf dem PC. Dann entwicklen des ganzen. Dazu muss das trainierte Netz, welches im
vorangegangenen Kapitel erstellt wurde heruntergeladen werden. Dann in Tensorflow.JS einbinden und nutzen. Also einen
Wrapper bauen.

Gerade interessant für On The Edge Sachen oder für Mobile.

Damit die Applikation auch im Internet zur Verfügung steht und vom Frontend über das API Connect aufgerufen werden kann,
muss diese in einen Cloud Foundry-Container, welcher in der IBM Cloud läuft, installiert werden. Im folgenden Kapitel
werden die dafür nötigen Schritte erläutert.

\subsection{Toolchain einrichten}
Da die Node.JS-Applikation nun entwickelt ist, soll diese in einem Cloud Foundry-Container installiert und abrufbar
gemacht werden. Damit dies nicht manuell nach jeder Änderung im Quellcode über \texttt{cf push} gemacht werden muss, kann
eine Toolchain aus der IBM Cloud genutzt werden.

Für die Nutzung der Toolchain wird ein Git-Repository angelegt. Nach jedem \texttt{commit}, welcher in dieses Repository
geladen wird, aktiviert sich die Toolchain selbstständig und lädt den entsprechenden Commit herunter.

Anschließend werden, je nach gewählter und eingerichteter Konfiguration, verschiedene Toolchain-Schritte durchlaufen, um
die Applikation in einen Cloud Foundry-Container zu installieren.

Dabei können die einzelnen Schritte, welche beim Deployment durchlaufen werden, selbst definiert, oder eine
vorkonfigurierte Toolchain genutzt werden. Die vorkonfigurierte Toolchain kann im Nachgang allerdings individuell
angepasst werden. Sie dient lediglich dem schnelleren Start.

Für die Konfiguration der Toolchain muss die instanziierte Node.JS-Runtime, in welcher die entwickelte Applikation laufen
soll, in dem IBM Cloud Dashboard ausgewählt werden.

Auf der folgenden Seite, im Tab \texttt{Übersicht}, erscheinen fünf Kacheln mit unterschiedlichen Informationen. Für die
Toolchain ist die Karte mit der Aufschritf \texttt{Continous Delivery} entscheiden. Dort erscheint ein Button mit der
Aufschrift \texttt{Aktivieren}.

Ein klick auf diesen öffnet die Übersicht und eine visuelle Vorschau der Standardkonfiguration der Toolchain. Nun kann ein
Name eingetragen und die Region ausgewählt werden, in der die Toolchain installiert werden soll. Da die Standardkonfiguration
vorerst völlig ausreichend ist, kann diese direkt übernommen werden. Dafür genügt ein klick auf \texttt{Erstellen}.

Nach einem kurzen Ladevorgang wurde die Toolchain eingerichtet und vorkonfiguriert. Es erscheinen nun vier Karten für
unterschiedliche Bereiche, in denen die IBM Cloud dem Entwicklungszyklus helfen kann.

Im Bereich \texttt{Nachdenken}, wird ein Issue-Tracker konfiguriert, in dem zum Beispiel Bugs (Softwarefehler), welche
in der Software entdeckt werden, eingetragen, verwaltet und diskutiert werden können.

In \texttt{Codieren} kann auf gleich zwei Kacheln zugegriffen werden. Einerseits auf das konfigurierte Git-Repository,
bei dem es sich um ein auf IBM-Servern gehostetet GitLab handelt. Andererseits findet sich dort eine Web-IDE, auf Basis
von Eclipse Orion, mit der der Quellcode der Anwendung online editiert werden kann.

Im der letzten Kategorie, \texttt{Bereitstellen}, findet sich die Toolchain, welche im nächsten Schritt Konfiguriert werden
muss. Ein klick auf die Kachel \texttt{Delivery Pipeline} öffnet diese.

Nach dem Laden der Seite erscheinen zwei sogenannte \texttt{Phasen} (engl. Stages). Jeder Schritt in der Delivery Pipeline
wird durch eine Phase symbolisiert. In einer Phase kann zum Beispiel der Quellcode aus dem Git-Repository geladen, oder
die geschriebenen Tests können durchgeführt werden.

Die Standardkonfiguration sieht in der \texttt{Build Stage} das herunterladen des Quellcodes aus dem Git-Repository vor
und in der \texttt{Deploy Stage} das Einrichten eines Cloud Foundy-Containers.

Für die Node.JS-Applikation reicht diese Konfiguration völlig aus, da keine zusätzlichen Installationen durchgeführt
werden müssen.

Jetzt muss der geschriebene Quellcode lediglich noch in das, in der Toolchain hinzugefügte Git-Repository, eingecheckt
werden. Die URL für das Repository kann in der Toolchain-Übersicht mit einem klick auf die Kachel \texttt{Git} angezeigt
werden.

Nach erfolgreichem hochladen der Anwendung startet der Deployvorgang in der Toolchain automatisch. Nach wenigen Minuten
sollte die Anwendung über ihre URL aufrufbar sein.

Da die Applikation nun im Internet über ein Cloud Foundry-Container zur Verfügung steht, kann diese im nächsten Schritt
mit dem API Connect Service verbunden werden. Dieser Schritt ist nötig, damit die Schnittstelle der Applikation vom
Frontend, welches in Kapitel~\ref{subsec:webseite} auf Seite~\pageref{subsec:webseite} beschrieben wird, und über Postman
vereinfacht und aufgerufen werden kann.

\subsection{API Connect}
Aufbauen von API Connect. Warum braucht man das? CORS-Problem. Beide Applikationen müssen abgefangen werden können. Also
auch zwei Routen. Das ist wichtig. Wie sieht das dann aus etc.
\\ \\
While this mechanism works for smaller teams and projects I’d guess that at some point you’d want API management
capabilities so that developers don’t have to have the credentials of the machine learning service and so that you can
better track the REST API invocations.